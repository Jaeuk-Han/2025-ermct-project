#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
119 EMS ì „ìš© â€“ Whisper large + SBAR v3 + KTAS 1/2/3 ë¶„ë¥˜ ì—”ì§„ (ì™„ì „ ì •ìƒì‘ë™ ë²„ì „)
âœ” CPR/AED íŒŒì‹± ì •ìƒí™”
âœ” SBAR êµ¬ì¡° ì •ìƒí™”
âœ” KTAS ë¡œì§ ì•ˆì •í™”
"""
import tempfile
from typing import Union, IO
import os
import re
from difflib import SequenceMatcher, get_close_matches
import whisper
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# ============================================================
# 0. í™˜ê²½ ì„¤ì • ë° ëª¨ë¸ ì¤€ë¹„
# ============================================================

# ìºì‹œ ê²½ë¡œ ì„¤ì • (í•„ìš”ì‹œ ìˆ˜ì •, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©ë˜ë¯€ë¡œ ì£¼ì„ì²˜ë¦¬í•´ë„ ë¨)
os.environ["XDG_CACHE_HOME"] = r"C:\whisper_cache"
os.environ["WHISPER_CACHE_DIR"] = r"C:\whisper_cache"

# API KEY (ì‚¬ìš©ì ê´€ë¦¬)
# ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” os.environ.get("OPENAI_API_KEY") ê¶Œì¥
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("âš ï¸ ê²½ê³ : .env íŒŒì¼ì— OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")

client = OpenAI(api_key=OPENAI_API_KEY)

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ì„ ì–¸ (ì²˜ìŒì—” ë¹„ì›Œë‘ )
whisper_model = None

def get_whisper_model():
    """
    ì„œë²„ ì‹¤í–‰ ì‹œì ì´ ì•„ë‹ˆë¼, ì‹¤ì œ í•„ìš”í•  ë•Œ ëª¨ë¸ì„ ë¡œë“œí•˜ê±°ë‚˜
    main.pyì˜ startup ì´ë²¤íŠ¸ì—ì„œ í˜¸ì¶œí•˜ì—¬ ë¡œë“œí•¨ (ì§€ì—° ë¡œë”©)
    """
    global whisper_model
    if whisper_model is None:
        print("[INFO] Whisper large ëª¨ë¸ ë¡œë”© ì¤‘...")
        # ëª¨ë¸ ì‚¬ì´ì¦ˆ ë³€ê²½ ê°€ëŠ¥: "base", "small", "medium", "large-v3"
        whisper_model = whisper.load_model("large-v3")
        print("[INFO] Whisper large ë¡œë”© ì™„ë£Œ.")
    return whisper_model


# ============================================================
# 1. Whisper STT
# ============================================================
def speech_to_text(audio_source: Union[str, IO]) -> str:
    """
    audio_source:
      - str : íŒŒì¼ ê²½ë¡œ
      - IO  : FastAPI UploadFile.file ê°™ì€ íŒŒì¼ ê°ì²´
    """
    # â˜… ì—¬ê¸°ì„œ ëª¨ë¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤ (ì—†ìœ¼ë©´ ë¡œë”©)
    model = get_whisper_model()

    # 1) ê²½ë¡œ(str)ë¡œ ë“¤ì–´ì˜¨ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if isinstance(audio_source, str):
        audio_path = audio_source
        delete_after = False
    else:
        # 2) íŒŒì¼ ê°ì²´ì¸ ê²½ìš° â†’ ì„ì‹œ íŒŒì¼ì— ì €ì¥ í›„ ê²½ë¡œë¡œ ì „ë‹¬
        delete_after = True
        with tempfile.NamedTemporaryFile(suffix=".m4a", delete=False) as tmp:
            # íŒŒì¼ í¬ì¸í„° ë§¨ ì•ìœ¼ë¡œ ëŒë ¤ë†“ê¸°
            try:
                audio_source.seek(0)
            except Exception:
                pass
            chunk = audio_source.read()
            tmp.write(chunk)
            audio_path = tmp.name

    try:
        # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤ë©´ fp16=True, ì•„ë‹ˆë©´ False (ìë™ ì²˜ë¦¬ë¨)
        result = model.transcribe(audio_path, language="ko")
        return result["text"].strip()
    finally:
        if delete_after:
            try:
                os.remove(audio_path)
            except Exception:
                pass



SEOUL_HOSPITAL_DB = [
    "ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ê°•ë‚¨ì„¸ë¸Œë€ìŠ¤ë³‘ì›",
    "ì‚¼ì„±ì„œìš¸ë³‘ì›",
    "ê°•ë™ê²½í¬ëŒ€í•™êµì˜ëŒ€ë³‘ì›",
    "ì„±ì‹¬ì˜ë£Œì¬ë‹¨ê°•ë™ì„±ì‹¬ë³‘ì›",
    "í•œêµ­ë³´í›ˆë³µì§€ì˜ë£Œê³µë‹¨ì¤‘ì•™ë³´í›ˆë³‘ì›",
    "ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ì„œìš¸ë³‘ì›",
    "ë¶€ë¯¼ë³‘ì›",
    "ì˜ë£Œë²•ì¸ì„œìš¸íš¨ì²œì˜ë£Œì¬ë‹¨ì—ì´ì¹˜í”ŒëŸ¬ìŠ¤ì–‘ì§€ë³‘ì›",
    "ê±´êµ­ëŒ€í•™êµë³‘ì›",
    "í˜œë¯¼ë³‘ì›",
    "ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†êµ¬ë¡œë³‘ì›",
    "êµ¬ë¡œì„±ì‹¬ë³‘ì›",
    "í¬ëª…ë³‘ì›",
    "ì¸ì œëŒ€í•™êµìƒê³„ë°±ë³‘ì›",
    "ë…¸ì›ì„ì§€ëŒ€í•™êµë³‘ì›",
    "í•œêµ­ì›ìë ¥ì˜í•™ì›ì›ìë ¥ë³‘ì›",
    "ì˜ë£Œë²•ì¸í•œì „ì˜ë£Œì¬ë‹¨í•œì¼ë³‘ì›",
    "ê²½í¬ëŒ€í•™êµë³‘ì›",
    "ì‚¼ìœ¡ì„œìš¸ë³‘ì›",
    "ì„œìš¸íŠ¹ë³„ì‹œë™ë¶€ë³‘ì›",
    "ì„œìš¸ì„±ì‹¬ë³‘ì›",
    "ì„œìš¸íŠ¹ë³„ì‹œë³´ë¼ë§¤ë³‘ì›",
    "ì¤‘ì•™ëŒ€í•™êµë³‘ì›",
    "ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ì„¸ë¸Œë€ìŠ¤ë³‘ì›",
    "ì˜ë£Œë²•ì¸ë™ì‹ ì˜ë£Œì¬ë‹¨ë™ì‹ ë³‘ì›",
    "í•™êµë²•ì¸ê°€í†¨ë¦­í•™ì›ê°€í†¨ë¦­ëŒ€í•™êµì„œìš¸ì„±ëª¨ë³‘ì›",
    "í•œì–‘ëŒ€í•™êµë³‘ì›",
    "í•™êµë²•ì¸ê³ ë ¤ì¤‘ì•™í•™ì›ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ë³‘ì›(ì•ˆì•”ë³‘ì›)",
    "ì¬ë‹¨ë²•ì¸ì•„ì‚°ì‚¬íšŒë³µì§€ì¬ë‹¨ì„œìš¸ì•„ì‚°ë³‘ì›",
    "ê²½ì°°ë³‘ì›",
    "ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ëª©ë™ë³‘ì›",
    "í™ìµë³‘ì›",
    "ì„œìš¸íŠ¹ë³„ì‹œì„œë‚¨ë³‘ì›",
    "ê°€í†¨ë¦­ëŒ€í•™êµì—¬ì˜ë„ì„±ëª¨ë³‘ì›",
    "í•œë¦¼ëŒ€í•™êµê°•ë‚¨ì„±ì‹¬ë³‘ì›",
    "ì„±ì• ì˜ë£Œì¬ë‹¨ì„±ì• ë³‘ì›",
    "ëª…ì§€ì„±ëª¨ë³‘ì›",
    "ëŒ€ë¦¼ì„±ëª¨ë³‘ì›",
    "ìˆœì²œí–¥ëŒ€í•™êµë¶€ì†ì„œìš¸ë³‘ì›",
    "ê°€í†¨ë¦­ëŒ€í•™êµì€í‰ì„±ëª¨ë³‘ì›",
    "ì˜ë£Œë²•ì¸ì²­êµ¬ì„±ì‹¬ë³‘ì›",
    "ì„œìš¸ëŒ€í•™êµë³‘ì›",
    "ê°•ë¶ì‚¼ì„±ë³‘ì›",
    "ì„œìš¸ì ì‹­ìë³‘ì›",
    "ì„¸ë€ë³‘ì›",
    "êµ­ë¦½ì¤‘ì•™ì˜ë£Œì›",
    "ì„œìš¸íŠ¹ë³„ì‹œì„œìš¸ì˜ë£Œì›",
    "ì˜ë£Œë²•ì¸í’ì‚°ì˜ë£Œì¬ë‹¨ë™ë¶€ì œì¼ë³‘ì›",
    "ë…¹ìƒ‰ë³‘ì›"
]

STATIC_MAP = {
    # ============================================
    # 1) ì„¸ë¸Œë€ìŠ¤ ê³„ì—´
    # ============================================
    # ë³¸ì›(ì‹ ì´Œ)
    "ì„¸ë¸Œë€ìŠ¤": "ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ì„¸ë¸Œë€ìŠ¤ë³‘ì›",
    "ì„¸ë¸Œ": "ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ì„¸ë¸Œë€ìŠ¤ë³‘ì›",
    "ë³¸ì„¸ë¸Œ": "ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ì„¸ë¸Œë€ìŠ¤ë³‘ì›",
    "ì‹ ì´Œì„¸ë¸Œ": "ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ì„¸ë¸Œë€ìŠ¤ë³‘ì›",

    # ê°•ë‚¨ ì„¸ë¸Œë€ìŠ¤
    "ê°•ë‚¨ì„¸ë¸Œë€ìŠ¤": "ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ê°•ë‚¨ì„¸ë¸Œë€ìŠ¤ë³‘ì›",
    "ê°•ë‚¨ì„¸ë¸Œ": "ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ê°•ë‚¨ì„¸ë¸Œë€ìŠ¤ë³‘ì›",
    "ê°•ì„¸ë¸Œ": "ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ê°•ë‚¨ì„¸ë¸Œë€ìŠ¤ë³‘ì›",

    # ============================================
    # 2) ì„±ëª¨ ê³„ì—´
    # ============================================
    # ì„œìš¸ ì„±ëª¨
    "ì„œìš¸ì„±ëª¨": "í•™êµë²•ì¸ê°€í†¨ë¦­í•™ì›ê°€í†¨ë¦­ëŒ€í•™êµì„œìš¸ì„±ëª¨ë³‘ì›",
    "ë°˜í¬ì„±ëª¨": "í•™êµë²•ì¸ê°€í†¨ë¦­í•™ì›ê°€í†¨ë¦­ëŒ€í•™êµì„œìš¸ì„±ëª¨ë³‘ì›",

    # ì—¬ì˜ë„ ì„±ëª¨
    "ì—¬ì˜ë„ì„±ëª¨": "ê°€í†¨ë¦­ëŒ€í•™êµì—¬ì˜ë„ì„±ëª¨ë³‘ì›",
    "ì—¬ì„±ëª¨": "ê°€í†¨ë¦­ëŒ€í•™êµì—¬ì˜ë„ì„±ëª¨ë³‘ì›",

    # ì€í‰ ì„±ëª¨
    "ì€í‰ì„±ëª¨": "ê°€í†¨ë¦­ëŒ€í•™êµì€í‰ì„±ëª¨ë³‘ì›",

    # ============================================
    # 3) ê³ ë ¤ëŒ€ ê³„ì—´
    # ============================================
    # ê³ ëŒ€ ì•ˆì•”
    "ì•ˆì•”": "í•™êµë²•ì¸ê³ ë ¤ì¤‘ì•™í•™ì›ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ë³‘ì›(ì•ˆì•”ë³‘ì›)",
    "ê³ ëŒ€ì•ˆì•”": "í•™êµë²•ì¸ê³ ë ¤ì¤‘ì•™í•™ì›ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ë³‘ì›(ì•ˆì•”ë³‘ì›)",

    # ê³ ëŒ€ êµ¬ë¡œ
    "êµ¬ë¡œê³ ëŒ€": "ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†êµ¬ë¡œë³‘ì›",
    "ê³ ëŒ€êµ¬ë¡œ": "ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†êµ¬ë¡œë³‘ì›",
    "ê³ ëŒ€ êµ¬ë¡œ": "ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†êµ¬ë¡œë³‘ì›",

    # ============================================
    # 4) ì´ëŒ€(ì´í™”ì—¬ëŒ€) ê³„ì—´
    # ============================================
    # ì´ëŒ€ ì„œìš¸
    "ì´ëŒ€ì„œìš¸": "ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ì„œìš¸ë³‘ì›",
    "ì´ëŒ€ ì„œìš¸": "ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ì„œìš¸ë³‘ì›",
    "ì´í™”ì„œìš¸": "ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ì„œìš¸ë³‘ì›",

    # ì´ëŒ€ ëª©ë™
    "ì´ëŒ€ëª©ë™": "ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ëª©ë™ë³‘ì›",
    "ëª©ë™ì´ëŒ€": "ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ëª©ë™ë³‘ì›",
    "ëª©ë™ ë³‘ì›": "ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ëª©ë™ë³‘ì›",

    # ============================================
    # 5) ì‚¼ì„± ê³„ì—´
    # ============================================
    # ì‚¼ì„±ì„œìš¸ë³‘ì›
    "ì‚¼ì„±ì„œìš¸": "ì‚¼ì„±ì„œìš¸ë³‘ì›",
    "ì‚¼ì„± ë³‘ì›": "ì‚¼ì„±ì„œìš¸ë³‘ì›",
    "smc": "ì‚¼ì„±ì„œìš¸ë³‘ì›",

    # ê°•ë¶ì‚¼ì„±ë³‘ì›
    "ê°•ë¶ì‚¼ì„±": "ê°•ë¶ì‚¼ì„±ë³‘ì›",
    "ê°•ë¶ ì‚¼ì„±": "ê°•ë¶ì‚¼ì„±ë³‘ì›",

    # ============================================
    # 6) ì„±ì‹¬ ê³„ì—´
    # ============================================
    # ê°•ë™ì„±ì‹¬
    "ê°•ë™ì„±ì‹¬": "ì„±ì‹¬ì˜ë£Œì¬ë‹¨ê°•ë™ì„±ì‹¬ë³‘ì›",
    # êµ¬ë¡œì„±ì‹¬
    "êµ¬ë¡œì„±ì‹¬": "êµ¬ë¡œì„±ì‹¬ë³‘ì›",
    # ì²­êµ¬ì„±ì‹¬
    "ì²­êµ¬ì„±ì‹¬": "ì˜ë£Œë²•ì¸ì²­êµ¬ì„±ì‹¬ë³‘ì›",

    
}

# ============================================================
# LLM ë³´ì • í•¨ìˆ˜ (ì—¬ê¸°ì— ì¶”ê°€)
# ============================================================


def llm_clean_text(raw_text: str) -> str:
    """
    OpenAI GPT-4.1-mini ê¸°ë°˜ ìŒì„± ì¸ì‹ ë¬¸ì¥ ë³´ì •
    - ìˆ«ì ë³´ì¡´
    - ë³‘ì›ëª…Â·ì˜ë£Œìš©ì–´ ë³´ì •
    - ë¬¸ì¥ êµ¬ì¡° ìœ ì§€
    """

    prompt = f"""
ë‹¹ì‹ ì€ 119 êµ¬ê¸‰ëŒ€ì›ì˜ ì‘ê¸‰ì‹¤ ì „í™”ë³´ê³  ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•˜ê²Œ ë³´ì •í•˜ëŠ” LLMì…ë‹ˆë‹¤.

[ëª©í‘œ]
- STT ì›ë¬¸ì˜ ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ë©° í•œêµ­ì–´ ë¬¸ì¥ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬í•©ë‹ˆë‹¤.
- ìˆ«ì(ë‚˜ì´Â·í˜ˆì••Â·ë§¥ë°•Â·í˜¸í¡ìˆ˜Â·SpOâ‚‚Â·ì²´ì˜¨ ë“±)ëŠ” ë³€ê²½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ë³‘ì›ëª…ì€ ë°˜ë“œì‹œ ì œê³µëœ ë³‘ì›ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ë¡œ ë³´ì •í•©ë‹ˆë‹¤.
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë³‘ì›ëª…ì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- â€œí‰ì†Œ ë‹¤ë‹ˆë˜/ì™¸ë˜/íŒ”ë¡œì—…â€ ì–¸ê¸‰ ì‹œ ë³‘ì› ë³´ì • ê·œì¹™ì„ ì ìš©í•©ë‹ˆë‹¤.

[ë³‘ì›ëª… ë³´ì • ê·œì¹™]
STTì›ë¬¸ì— ê¸°ì¬ëœ ë³‘ì›ëª…ì´ ì •ì‹ ë³‘ì›ëª… ë¦¬ìŠ¤íŠ¸ì— ìˆë‹¤ë©´ STTì›ë¬¸ì— ê¸°ì¬ëœ ë³‘ì›ëª… ê·¸ëŒ€ë¡œ ë†”ë‘¡ë‹ˆë‹¤.
ë‹¤ìŒ ë‹¨ì¶•/ë¹„í‘œì¤€ ëª…ì¹­ì€ â†’ ì˜¤ë¥¸ìª½ì˜ ì •ì‹ ë³‘ì›ëª…ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
ì„¸ë¸Œë€ìŠ¤/ì„¸ë¸Œ/ë³¸ì„¸ë¸Œ/ì‹ ì´Œì„¸ë¸Œ â†’ ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ì„¸ë¸Œë€ìŠ¤ë³‘ì›
ê°•ë‚¨ì„¸ë¸Œë€ìŠ¤/ê°•ë‚¨ì„¸ë¸Œ/ê°•ì„¸ë¸Œ â†’ ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ê°•ë‚¨ì„¸ë¸Œë€ìŠ¤ë³‘ì›
ì„œìš¸ì„±ëª¨/ë°˜í¬ì„±ëª¨ â†’ í•™êµë²•ì¸ê°€í†¨ë¦­í•™ì›ê°€í†¨ë¦­ëŒ€í•™êµì„œìš¸ì„±ëª¨ë³‘ì›
ì—¬ì˜ë„ì„±ëª¨/ì—¬ì„±ëª¨/ì—¬ì˜ì„±ëª¨ â†’ ê°€í†¨ë¦­ëŒ€í•™êµì—¬ì˜ë„ì„±ëª¨ë³‘ì›
ì€í‰ì„±ëª¨ â†’ ê°€í†¨ë¦­ëŒ€í•™êµì€í‰ì„±ëª¨ë³‘ì›
ì•ˆì•”/ê³ ëŒ€ì•ˆì•” â†’ í•™êµë²•ì¸ê³ ë ¤ì¤‘ì•™í•™ì›ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ë³‘ì›(ì•ˆì•”ë³‘ì›)
êµ¬ë¡œê³ ëŒ€/ê³ ëŒ€êµ¬ë¡œ â†’ ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†êµ¬ë¡œë³‘ì›
ì´ëŒ€ì„œìš¸/ì´í™”ì„œìš¸ â†’ ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ì„œìš¸ë³‘ì›
ì´ëŒ€ëª©ë™/ëª©ë™ì´ëŒ€/ëª©ë™ ë³‘ì› â†’ ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ëª©ë™ë³‘ì›
ì‚¼ì„±ì„œìš¸/ì‚¼ì„± ë³‘ì›/smc â†’ ì‚¼ì„±ì„œìš¸ë³‘ì›
ê°•ë¶ì‚¼ì„± â†’ ê°•ë¶ì‚¼ì„±ë³‘ì›
ê°•ë™ì„±ì‹¬ â†’ ì„±ì‹¬ì˜ë£Œì¬ë‹¨ê°•ë™ì„±ì‹¬ë³‘ì›
36ë³‘ì›/36/ì‚¼ìœ¡ â†’ ì‚¼ìœ¡ì„œìš¸ë³‘ì›
êµ¬ë¡œì„±ì‹¬ â†’ êµ¬ë¡œì„±ì‹¬ë³‘ì›
ì²­êµ¬ì„±ì‹¬ â†’ ì˜ë£Œë²•ì¸ì²­êµ¬ì„±ì‹¬ë³‘ì›
ê°•ë‚¨ì„±ì‹¬ â†’ í•œë¦¼ëŒ€í•™êµê°•ë‚¨ì„±ì‹¬ë³‘ì›
ì„œìš¸ëŒ€/ì„œìš¸ëŒ€ë³‘ì› â†’ ì„œìš¸ëŒ€í•™êµë³‘ì›
ì•„ì‚°ë³‘ì›/ì„œìš¸ì•„ì‚° â†’ ì¬ë‹¨ë²•ì¸ì•„ì‚°ì‚¬íšŒë³µì§€ì¬ë‹¨ì„œìš¸ì•„ì‚°ë³‘ì›
ë³´ë¼ë§¤ â†’ ì„œìš¸íŠ¹ë³„ì‹œë³´ë¼ë§¤ë³‘ì›
ì„œë‚¨ë³‘ì›/ì„œë‚¨ â†’ ì„œìš¸íŠ¹ë³„ì‹œì„œë‚¨ë³‘ì›

[ì •ì‹ ë³‘ì›ëª… ë¦¬ìŠ¤íŠ¸]
(ì´ ë¦¬ìŠ¤íŠ¸ëŠ” ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€)  
ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ê°•ë‚¨ì„¸ë¸Œë€ìŠ¤ë³‘ì›  
ì‚¼ì„±ì„œìš¸ë³‘ì›  
ê°•ë™ê²½í¬ëŒ€í•™êµì˜ëŒ€ë³‘ì›  
ì„±ì‹¬ì˜ë£Œì¬ë‹¨ê°•ë™ì„±ì‹¬ë³‘ì›  
í•œêµ­ë³´í›ˆë³µì§€ì˜ë£Œê³µë‹¨ì¤‘ì•™ë³´í›ˆë³‘ì›  
ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ì„œìš¸ë³‘ì›  
ë¶€ë¯¼ë³‘ì›  
ì˜ë£Œë²•ì¸ì„œìš¸íš¨ì²œì˜ë£Œì¬ë‹¨ì—ì´ì¹˜í”ŒëŸ¬ìŠ¤ì–‘ì§€ë³‘ì›  
ê±´êµ­ëŒ€í•™êµë³‘ì›  
í˜œë¯¼ë³‘ì›  
ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†êµ¬ë¡œë³‘ì›  
êµ¬ë¡œì„±ì‹¬ë³‘ì›  
í¬ëª…ë³‘ì›  
ì¸ì œëŒ€í•™êµìƒê³„ë°±ë³‘ì›  
ë…¸ì›ì„ì§€ëŒ€í•™êµë³‘ì›  
í•œêµ­ì›ìë ¥ì˜í•™ì›ì›ìë ¥ë³‘ì›  
ì˜ë£Œë²•ì¸í•œì „ì˜ë£Œì¬ë‹¨í•œì¼ë³‘ì›  
ê²½í¬ëŒ€í•™êµë³‘ì›  
ì‚¼ìœ¡ì„œìš¸ë³‘ì›  
ì„œìš¸íŠ¹ë³„ì‹œë™ë¶€ë³‘ì›  
ì„œìš¸ì„±ì‹¬ë³‘ì›  
ì„œìš¸íŠ¹ë³„ì‹œë³´ë¼ë§¤ë³‘ì›  
ì¤‘ì•™ëŒ€í•™êµë³‘ì›  
ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ì„¸ë¸Œë€ìŠ¤ë³‘ì›  
ì˜ë£Œë²•ì¸ë™ì‹ ì˜ë£Œì¬ë‹¨ë™ì‹ ë³‘ì›  
í•™êµë²•ì¸ê°€í†¨ë¦­í•™ì›ê°€í†¨ë¦­ëŒ€í•™êµì„œìš¸ì„±ëª¨ë³‘ì›  
í•œì–‘ëŒ€í•™êµë³‘ì›  
í•™êµë²•ì¸ê³ ë ¤ì¤‘ì•™í•™ì›ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ë³‘ì›(ì•ˆì•”ë³‘ì›)  
ì¬ë‹¨ë²•ì¸ì•„ì‚°ì‚¬íšŒë³µì§€ì¬ë‹¨ì„œìš¸ì•„ì‚°ë³‘ì›  
ê²½ì°°ë³‘ì›  
ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ëª©ë™ë³‘ì›  
í™ìµë³‘ì›  
ì„œìš¸íŠ¹ë³„ì‹œì„œë‚¨ë³‘ì›  
ê°€í†¨ë¦­ëŒ€í•™êµì—¬ì˜ë„ì„±ëª¨ë³‘ì›  
í•œë¦¼ëŒ€í•™êµê°•ë‚¨ì„±ì‹¬ë³‘ì›  
ì„±ì• ì˜ë£Œì¬ë‹¨ì„±ì• ë³‘ì›  
ëª…ì§€ì„±ëª¨ë³‘ì›  
ëŒ€ë¦¼ì„±ëª¨ë³‘ì›  
ìˆœì²œí–¥ëŒ€í•™êµë¶€ì†ì„œìš¸ë³‘ì›  
ê°€í†¨ë¦­ëŒ€í•™êµì€í‰ì„±ëª¨ë³‘ì›  
ì˜ë£Œë²•ì¸ì²­êµ¬ì„±ì‹¬ë³‘ì›  
ì„œìš¸ëŒ€í•™êµë³‘ì›  
ê°•ë¶ì‚¼ì„±ë³‘ì›  
ì„œìš¸ì ì‹­ìë³‘ì›  
ì„¸ë€ë³‘ì›  
êµ­ë¦½ì¤‘ì•™ì˜ë£Œì›  
ì„œìš¸íŠ¹ë³„ì‹œì„œìš¸ì˜ë£Œì›  
ì˜ë£Œë²•ì¸í’ì‚°ì˜ë£Œì¬ë‹¨ë™ë¶€ì œì¼ë³‘ì›  
ë…¹ìƒ‰ë³‘ì›  

[ì£¼í˜¸ì†Œ í‘œí˜„ ë³´ì • ê·œì¹™]
- ì„±ë³„Â·ë‚˜ì´ ë¬¸ì¥ ë’¤ì—ì„œ â€œì£¼í˜¸/ì£¼ã…â€ í˜•íƒœê°€ ë“±ì¥í•˜ê³  ì¦ìƒì„ ì˜ë¯¸í•˜ë©´ â†’ â€œì£¼í˜¸ì†Œâ€ë¡œ ìˆ˜ì •.

[ì˜í•™ ìš©ì–´ ìŒì„± ì˜¤ë¥˜ ë³´ì •]
ë¬¸ë§¥ìƒ ì´ìƒí•œ í•œêµ­ì–´ ë‹¨ì–´ê°€ ë“±ì¥í•˜ë©´ ë°œìŒ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ì˜ì–´ ì˜í•™ ì•½ì–´ë¡œ ìˆ˜ì •í•©ë‹ˆë‹¤.
ì˜ˆ:
í•´ë„ë¹„/ì• ë„ë¹„/ì—”ì•Œ â†’ NRB  
ë‚˜ì˜/ë‚´ì ˆ/ì½”ì¤„ â†’ Nasal prong  
ë¸Œì´í…/ë¹„í… â†’ V-tach ë˜ëŠ” V-fib  
ë…¸ë§/ì—”ì—ìŠ¤ â†’ NS(Normal Saline)  

[AVPU ë³´ì • ê·œì¹™]
1) "ì˜ì‹ì€ A/V/P/U" í˜•íƒœë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©.  
2) ì•ŒíŒŒë²³ì´ ì—†ê³  í•œêµ­ì–´ë§Œ ìˆì„ ê²½ìš° ë°œìŒ ê¸°ë°˜ ë§¤í•‘:  
   - A: ì—ì´/ì—/ì• /ì´  
   - V: ë¸Œì´/ë¹„/ë¸Œì—/ë¹„ì—  
   - P: í”¼/í”¼ì—/í¼/í”¼í•´/í”„/í”„ì—  
   - U: ìœ /ìš°/ìœ¼  
ì…ë ¥ ë‚´ìš©ì„ ê°€ì¥ ìœ ì‚¬í•œ ê·¸ë£¹ì— ë§¤í•‘í•˜ì—¬ AÂ·VÂ·PÂ·U ì¤‘ í•˜ë‚˜ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.  
ìµœì¢… ë¬¸ì¥ì€ â€œì˜ì‹ì€ Xì…ë‹ˆë‹¤â€ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.

[ì¶œë ¥]
- ìì—°ìŠ¤ëŸ¬ìš´ ì‘ê¸‰ì „í™” ë³´ê³  ë¬¸ì¥ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.
- ì„¤ëª…ì„ ì¶”ê°€í•˜ì§€ ë§ê³  êµì •ëœ ë¬¸ì¥ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.

[ì…ë ¥ STT ì›ë¬¸]
{raw_text}


{raw_text}
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
        )
        return response.choices[0].message.content.strip()

    except Exception as e:
        print("\n[LLM ERROR]", str(e))
        return raw_text



def token_similarity(a: str, b: str) -> float:
    return SequenceMatcher(None, a, b).ratio()


def best_match_hospital(raw_text, hospital_db):
    """
    [ì„œìš¸ ì „ìš©] ë³‘ì›ëª… ë§¤ì¹­ ë¡œì§
    1ìˆœìœ„: ì£¼ìš” ëŒ€í•™ë³‘ì› ê³„ì—´ë³„ ê·œì¹™ (ì§€ì ëª… ìš°ì„  í™•ì¸)
    2ìˆœìœ„: STATIC_MAP (ë‹¨ìˆœ ë§¤í•‘)
    3ìˆœìœ„: Fuzzy Matching (ìœ ì‚¬ë„)
    """
    if not raw_text:
        return None

    text = raw_text.strip()
    norm = text.replace(" ", "")

    # -----------------------------
    # 1) ì£¼ìš” ëŒ€í•™ë³‘ì› ê³„ì—´ë³„ ê·œì¹™ (ì„œìš¸ ì†Œì¬ë§Œ)
    # -----------------------------

    # [1] ì„¸ë¸Œë€ìŠ¤ (ì—°ì„¸ëŒ€)
    # â˜… "ê°•ë‚¨"ì´ ìˆëŠ”ì§€ ë¨¼ì € ë³´ê³  -> ì—†ìœ¼ë©´ ì‹ ì´Œ(ë³¸ì›)
    if ("ì„¸ë¸Œë€ìŠ¤" in norm) or ("ì„¸ë¸Œ" in norm):
        if "ê°•ë‚¨" in norm:
            return "ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ê°•ë‚¨ì„¸ë¸Œë€ìŠ¤ë³‘ì›"
        return "ì—°ì„¸ëŒ€í•™êµì˜ê³¼ëŒ€í•™ì„¸ë¸Œë€ìŠ¤ë³‘ì›"

    # [2] ì„±ëª¨ë³‘ì› (ê°€í†¨ë¦­ëŒ€)
    # ì—¬ì˜ë„, ì€í‰ ë¨¼ì € ì²´í¬ -> ë‚˜ë¨¸ì§€ëŠ” ì„œìš¸ì„±ëª¨(ë°˜í¬)
    if "ì„±ëª¨" in norm:
        if "ì—¬ì˜ë„" in norm or "ì—¬ì„±ëª¨" in norm:
            return "ê°€í†¨ë¦­ëŒ€í•™êµì—¬ì˜ë„ì„±ëª¨ë³‘ì›"
        if "ì€í‰" in norm:
            return "ê°€í†¨ë¦­ëŒ€í•™êµì€í‰ì„±ëª¨ë³‘ì›"
        
        # ì£¼ì˜: "ëª…ì§€ì„±ëª¨", "ëŒ€ë¦¼ì„±ëª¨" ë“±ì€ ëŒ€í•™ë³‘ì›ì´ ì•„ë‹˜. 
        # ì´ë¥¼ ì œì™¸í•˜ê³  "ì„±ëª¨ë³‘ì›"ì´ë¼ê³ ë§Œ í–ˆì„ ë•Œ ì„œìš¸ì„±ëª¨ë¡œ ì—°ê²°
        if "ëª…ì§€" not in norm and "ëŒ€ë¦¼" not in norm:
            return "í•™êµë²•ì¸ê°€í†¨ë¦­í•™ì›ê°€í†¨ë¦­ëŒ€í•™êµì„œìš¸ì„±ëª¨ë³‘ì›"

    # [3] ê³ ë ¤ëŒ€ (ì•ˆì•”/êµ¬ë¡œ)
    # êµ¬ë¡œ ë¨¼ì € ì²´í¬ -> ë‚˜ë¨¸ì§€ëŠ” ì•ˆì•”
    if "ê³ ëŒ€" in norm or "ì•ˆì•”" in norm or ("êµ¬ë¡œ" in norm and "ê³ ëŒ€" in norm):
        if "êµ¬ë¡œ" in norm:
            return "ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†êµ¬ë¡œë³‘ì›"
        return "í•™êµë²•ì¸ê³ ë ¤ì¤‘ì•™í•™ì›ê³ ë ¤ëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ë³‘ì›(ì•ˆì•”ë³‘ì›)"

    # [4] ì´í™”ì—¬ëŒ€ (ì„œìš¸/ëª©ë™)
    # ëª©ë™ ë¨¼ì € ì²´í¬ -> ë‚˜ë¨¸ì§€ëŠ” ì„œìš¸(ë§ˆê³¡)
    if ("ì´ëŒ€" in norm) or ("ì´í™”" in norm):
        if "ëª©ë™" in norm:
            return "ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ëª©ë™ë³‘ì›"
        return "ì´í™”ì—¬ìëŒ€í•™êµì˜ê³¼ëŒ€í•™ë¶€ì†ì„œìš¸ë³‘ì›"

    # [5] ì‚¼ì„±ì„œìš¸ vs ê°•ë¶ì‚¼ì„±
    if "ì‚¼ì„±" in norm:
        if "ê°•ë¶" in norm:
            return "ê°•ë¶ì‚¼ì„±ë³‘ì›"
        # ê·¸ëƒ¥ "ì‚¼ì„±ë³‘ì›" í•˜ë©´ ì‚¼ì„±ì„œìš¸ë³‘ì›
        return "ì‚¼ì„±ì„œìš¸ë³‘ì›"
        
    # [6] ì„œìš¸ëŒ€
    if "ì„œìš¸ëŒ€" in norm:
        # ë³´ë¼ë§¤ë³‘ì›ì€ "ë³´ë¼ë§¤" í‚¤ì›Œë“œë¡œ STATIC_MAPì—ì„œ ì²˜ë¦¬ë¨
        # ë”°ë¼ì„œ ì—¬ê¸°ì„  í˜œí™”ë™ ë³¸ì›ë§Œ ì²˜ë¦¬
        if "ë³´ë¼ë§¤" not in norm:
            return "ì„œìš¸ëŒ€í•™êµë³‘ì›"

    # [7] ì•„ì‚°ë³‘ì›
    if "ì•„ì‚°" in norm:
        return "ì¬ë‹¨ë²•ì¸ì•„ì‚°ì‚¬íšŒë³µì§€ì¬ë‹¨ì„œìš¸ì•„ì‚°ë³‘ì›"
    
    # [8] ìˆœì²œí–¥ (ì„œìš¸)
    if "ìˆœì²œí–¥" in norm:
        return "ìˆœì²œí–¥ëŒ€í•™êµë¶€ì†ì„œìš¸ë³‘ì›"
    
    # [9] ìƒê³„ë°±ë³‘ì› (ì„œìš¸ì—” ìƒê³„ë°±ë§Œ ë‚¨ìŒ)
    if "ë°±ë³‘ì›" in norm:
        return "ì¸ì œëŒ€í•™êµìƒê³„ë°±ë³‘ì›"

    # -----------------------------
    # 2) STATIC_MAP ë§¤í•‘ (ë‚˜ë¨¸ì§€ ë³‘ì›ë“¤)
    # -----------------------------
    # í‚¤ ê¸¸ì´ê°€ ê¸´ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ì—¬ ë§¤ì¹­ (ì˜ˆ: 'ê°•ë™ì„±ì‹¬'ì´ 'ì„±ì‹¬'ë³´ë‹¤ ë¨¼ì € ê±¸ë¦¬ê²Œ)
    for key in sorted(STATIC_MAP.keys(), key=len, reverse=True):
        if key in norm:
            return STATIC_MAP[key]

    # -----------------------------
    # 3) Fuzzy Matching (ì´í•˜ ë™ì¼)
    # -----------------------------
    m = re.search(r'([ê°€-í£A-Za-z0-9\s]*ë³‘ì›)', text)
    if m:
        core = m.group(1).strip()
    else:
        core = text

    cleaned = core.replace(" ", "").replace("ë³‘ì›", "")
    tokens = re.findall(r"[ê°€-í£]+", cleaned)

    if not tokens:
        fallback = get_close_matches(core, hospital_db, n=1, cutoff=0.4)
        return fallback[0] if fallback else None

    best_hospital = None
    best_score = 0.0

    for hosp in hospital_db:
        hosp_clean = hosp.replace(" ", "")
        hosp_tokens = re.findall(r"[ê°€-í£]+", hosp_clean)

        score = 0.0
        for t in tokens:
            for ht in hosp_tokens:
                sim = token_similarity(t, ht)
                if sim > score:
                    score = sim

        if score > best_score:
            best_score = score
            best_hospital = hosp

    if best_score >= 0.70:
        return best_hospital

    fallback = get_close_matches(core, hospital_db, n=1, cutoff=0.5)
    return fallback[0] if fallback else None



# ============================================================
# 2. SBAR íŒŒì„œ
# ============================================================

PATTERNS = {
    "dyspnea": [
        r"ìˆ¨\s?ì°¨", r"ìˆ¨ì´ ì°¨", r"ìˆ¨ì´ ê°€ì˜", r"í˜¸í¡ê³¤ë€", r"ìˆ¨ ëª» ì‰¬",
        r"ê°€ìœ í˜¸í¡", r"í—ë–¡", r"ëŒ€í™”.*í˜ë“¤", r"ë§.*ëª»"
    ],
    "chest_pain": [r"ê°€ìŠ´.*ì•„íŒŒ", r"í‰í†µ", r"ê°€ìŠ´.*í†µì¦"],
    
    # â˜… ì‚¬ê³ ê¸°ì „ í•µì‹¬ íŒ¨í„´
    "mechanism": [
        r"êµí†µì‚¬ê³ ", r"ì‚¬ê³ ", r"ì¶”ëŒ", r"ì¶©ëŒ",
        r"ì •ë©´.*ì¶©ëŒ", r"ì¸¡ë©´.*ì¶©ëŒ", r"í›„ë°©.*ì¶”ëŒ",
        r"ë³´í–‰ì.*ì‚¬ê³ ", r"ì˜¤í† ë°”ì´", r"ìì „ê±°.*ì‚¬ê³ ",
        r"ì—ì–´ë°±", r"ì „ë³µ", r"ì•ˆì „ë²¨íŠ¸.*ì•ˆ",
        r"ë‚™ìƒ", r"ì¶”ë½",
        r"\d+.*ë¯¸í„°.*ë–¨ì–´"   # ì˜ˆ: "3ë¯¸í„°ì—ì„œ ë–¨ì–´ì§"
    ],

    "bleeding_severe": [r"ëŒ€ëŸ‰.*ì¶œí˜ˆ", r"í”¼.*ë¶„ì¶œ"],
    "anticoagulant": [r"í•­ì‘ê³ ì œ", r"ì™€íŒŒë¦°", r"ì—˜ë¦¬í€´ìŠ¤"],
}

CHIEF_COMPLAINT_KO = {
    "chest_pain": "ê°€ìŠ´ í†µì¦ (Chest pain)",
    "dyspnea": "í˜¸í¡ê³¤ë€ (Dyspnea)",
    "neuro": "ì‹ ê²½í•™ì  ì¦ìƒ (Stroke-like symptoms)",
    "abdominal": "ë³µí†µ/ì†Œí™”ê¸° ì¦ìƒ (Abdominal pain / GI symptoms)",
    "bleeding": "ì¶œí˜ˆ (External / GI bleeding)",
    "altered": "ì˜ì‹ ë³€í™” (Altered mental status)",
    "trauma": "ì™¸ìƒ (Trauma / burns / crush / amputation)",
    "obgyn": "ì‚°ë¶€ì¸ê³¼ ì‘ê¸‰ (OB-GYN emergency)",
    "pediatric": "ì†Œì•„ ì‘ê¸‰ (Pediatric emergency)",
    "psychiatric": "ì •ì‹ ê³¼ì  ì‘ê¸‰ (Psychiatric emergency)",
    None: "ì •ë³´ ì—†ìŒ"
}


def match_any(pattern_list, text):
    return any(re.search(p, text) for p in pattern_list)


# -------------------- A --------------------
def extract_avpu(text: str) -> str:
    t = text.replace(" ", "")

    # 1) "ì˜ì‹ì€ Vì…ë‹ˆë‹¤ / ì˜ì‹ì€ V" ë“± ë‹¤ í—ˆìš©
    m = re.search(r"(ì˜ì‹ì€|ì˜ì‹ìƒíƒœëŠ”|ì˜ì‹ìˆ˜ì¤€ì€|AVPUëŠ”)\s*([AVPU])", text, re.IGNORECASE)
    if m:
        return m.group(2).upper()

    # 2) "ì˜ì‹ Vì…ë‹ˆë‹¤", "ì˜ì‹ V", "ì˜ì‹ìƒíƒœ V" ë“±
    m = re.search(r"(ì˜ì‹|ì˜ì‹ìƒíƒœ|ì˜ì‹ìˆ˜ì¤€|AVPU)[ì€ëŠ”]?\s*([AVPU])", text, re.IGNORECASE)
    if m:
        return m.group(2).upper()

    # 3) í™•ì¥ íŒ¨í„´ â€“ Vë’¤ì— ê¸€ìê°€ ë¶™ì–´ë„ ì¡ê¸°
    m = re.search(r"ì˜ì‹[ì€ëŠ”]?\s*([AVPU])[^A-Za-z]?", text)
    if m:
        return m.group(1).upper()

    # 4) í’€ ë‹¨ì–´ ê¸°ë°˜
    if re.search(r"ì˜ì‹.*(ìˆ|ëª…ë£Œ)", text, re.IGNORECASE):
        return "A"
    if re.search(r"ì˜ì‹.*(verbal|ë²Œë²Œ)", text, re.IGNORECASE):
        return "V"
    if re.search(r"ì˜ì‹.*(pain|í˜ì¸|í†µì¦ë°˜ì‘)", text, re.IGNORECASE):
        return "P"
    if re.search(r"ì˜ì‹.*(unresponsive|ì—†|ë¬´ì˜ì‹)", text, re.IGNORECASE):
        return "U"

    return "A"



def parse_assessment_v3(text: str) -> dict:
    A = {
        "AVPU": "A",
        "BP_sys": None, "BP_dia": None,
        "HR": None, "RR": None, "SpO2": None,
        "BT": None,
        "pain_nrs": None,
        "dyspnea": False, "dyspnea_severity": None,
        "bleeding": False, "bleeding_severity": None
    }

    t = text

    # AVPU
    A["AVPU"] = extract_avpu(t)

    # â˜… BP : í˜ˆì••
    bp = re.search(
        r'(í˜ˆì••|bp|ë¹„í”¼|b/p)\D{0,10}?(\d{2,3})\D{0,5}[/ëŒ€\s]?\D{0,5}(\d{2,3})',
        t, re.IGNORECASE)
    if bp:
        A["BP_sys"] = int(bp.group(2))
        A["BP_dia"] = int(bp.group(3))

    # ====== í˜ˆì•• ìë™ ë³´ì • ë¡œì§ ======
    sbp = A["BP_sys"]
    dbp = A["BP_dia"]

    if sbp is not None and dbp is not None:
        # 1) SBP ì•ìë¦¬ ì˜ë¦¼ ë³´ì • (ì˜ˆ: 18/78 â†’ 118/78)
        if sbp < 60 and dbp >= 60:
            A["BP_sys"] = sbp + 100

        # 2) SBP í•œ ìë¦¬ ì˜ë¦¼ (ì˜ˆ: 6/70 â†’ 106/70)
        if sbp < 10 and dbp > 50:
            A["BP_sys"] = sbp + 100

        # 3) DBPê°€ ë¹„ì •ìƒì ìœ¼ë¡œ í° ê²½ìš° â†’ SpO2ë‚˜ HRì´ ì˜¤ì—¼ëœ ê²½ìš°
        #    ì˜ˆ: 118/104 (ì›ë˜ëŠ” 118/78)
        if dbp > 120 or dbp > sbp:
            # DBPëŠ” ë³´í†µ 40~110 ì‚¬ì´
            # sbp-dbp ì°¨ì´ê°€ ì´ìƒí•˜ë©´ DBPë¥¼ ë°”ë¡œ ì• ìˆ«ìë¡œ ì¬ì¶”ì¶œ
            candidates = re.findall(r'\d{2,3}', text)
        
            # candidates ì¤‘ SBP ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ê°€ì¥ í˜„ì‹¤ì ì¸ DBP ì„ íƒ
            possible_dbp = [int(x) for x in candidates if 40 <= int(x) <= 120 and int(x) < A["BP_sys"]]
            if possible_dbp:
                A["BP_dia"] = possible_dbp[-1]  # ë§ˆì§€ë§‰ í˜„ì‹¤ì ì¸ DBP ì„ íƒ

        # 4) SBP < DBP â†’ ë°˜ë“œì‹œ ì˜¤ë¥˜
        if A["BP_sys"] <= A["BP_dia"]:
            # SBPì— +100 ë³´ì •
            A["BP_sys"] += 100



    # â˜… HR : ë§¥ë°•
    hr = re.search(
        r'(ë§¥ë°•|ì‹¬ë°•ìˆ˜)\D*?(\d{2,3})',
        t, re.IGNORECASE)
    if hr:
        A["HR"] = int(hr.group(2))

    # â˜… RR : í˜¸í¡ìˆ˜
    rr = re.search(
        r'(í˜¸í¡ìˆ˜|í˜¸í¡)\D*?(\d{1,2})',
        t, re.IGNORECASE)
    if rr:
        A["RR"] = int(rr.group(2))

    # â˜… SpO2
    spo = re.search(r'(SpO2|ì‚°ì†Œ\s*í¬í™”[ë„ì]?|ì‚°ì†Œ)\D*(\d+)', t)
    if spo:
        A["SpO2"] = int(spo.group(2))

    # â˜… BT : ì²´ì˜¨
    bt = re.search(
        r'(ì²´ì˜¨|ì˜¨ë„)\D*?(\d{1,2}\.?\d{0,2})\D*(ë„|â„ƒ)?',
        t
    )
    if bt:
        A["BT"] = float(bt.group(2))

    # â˜… NRS : í†µì¦
    pain = re.search(
        r'(í†µì¦|nrs|ì—”ì•Œì—ìŠ¤)\D*?(\d{1,2})(?:[\.ì \s]*?(\d))?',
        t,
        re.IGNORECASE
    )
    if pain:
        base = int(pain.group(2))
        decimal = pain.group(3)
        if decimal:
            A["pain_nrs"] = float(f"{base}.{decimal}")
        else:
            A["pain_nrs"] = float(base)

    # dyspnea/bleeding ë¶€ë¶„
    if match_any(PATTERNS["dyspnea"], t):
        A["dyspnea"] = True
        if "ì‹¬í•œ" in t or "ë§" in t:
            A["dyspnea_severity"] = "severe"
        else:
            A["dyspnea_severity"] = "moderate"

    if match_any(PATTERNS["bleeding_severe"], t):
        A["bleeding"] = True
        A["bleeding_severity"] = "severe"
    elif "ì¶œí˜ˆ" in t:
        A["bleeding"] = True
        A["bleeding_severity"] = "moderate"

    return A


# -------------------- B --------------------
def parse_background_v3(text: str) -> dict:
    B = {
        "HTN": False, "DM": False, "HF": False,
        "anticoagulant": False,
        "high_risk": False,
        "pregnant": False,
        "recent_surgery": False,
    }

    if "ê³ í˜ˆì••" in text:
        B["HTN"] = True
    if "ë‹¹ë‡¨" in text:
        B["DM"] = True
    if "ì‹¬ë¶€ì „" in text:
        B["HF"] = True

    # â˜… ì‹¬ê·¼ê²½ìƒ‰/í˜‘ì‹¬ì¦ë„ high_riskì— í¬í•¨
    cad = False
    if "ì‹¬ê·¼ê²½ìƒ‰" in text or "í˜‘ì‹¬ì¦" in text or "ìŠ¤í…íŠ¸" in text:
        cad = True

    if match_any(PATTERNS["anticoagulant"], text):
        B["anticoagulant"] = True

    if "ì„ì‹ " in text:
        B["pregnant"] = True
    if "ìˆ˜ìˆ " in text:
        B["recent_surgery"] = True

    if B["HF"] or B["anticoagulant"] or cad:
        B["high_risk"] = True

    return B


# -------------------- S --------------------
def parse_situation_v3(text: str) -> dict:
    S = {
        "age": None,
        "gender": None,
        "chief_complaint": None,
        "mechanism": False,
        "followup_raw": None,   # ë³‘ì› ê´€ë ¨ êµ¬ê°„(raw)
        "requirement": None,    # ì´ì†¡/ì „ì›/ì²˜ì¹˜ í•„ìš” ì‚¬í•­
    }

    t = text

    # ------------------------- ì„±ë³„ -------------------------
    if "ë‚¨ì" in t or "ë‚¨ì„±" in t:
        S["gender"] = "M"
    if "ì—¬ì" in t or "ì—¬ì„±" in t:
        S["gender"] = "F"

    # ------------------------- ë‚˜ì´ -------------------------
    age = re.search(r'(\d+)\s*ì„¸', t)
    if age:
        S["age"] = int(age.group(1))


    # ------------------------- ì£¼í˜¸ì†Œ(10ê°œ ì²´ê³„) -------------------------
    cc_patterns = {
        "chest_pain": [
            r"ê°€ìŠ´", r"í‰í†µ", r"ì‹¬ì¥.*ì•„íŒŒ", r"CP", r"chest", r"í‰ë¶€.*í†µì¦", r"í‰ë¶€í†µì¦"
        ],
        "dyspnea": [
            r"ìˆ¨\s?ì°¨", r"í˜¸í¡ê³¤ë€", r"ìˆ¨.*ëª» ì‰¬", r"ìˆ¨ì´ ê°€ì˜", r"í˜¸í¡.*ê³¤ë€", r"í˜¸í¡ê³¤ë€"
        ],
        "neuro": [
            r"í¸ë§ˆë¹„", r"ë§ˆë¹„", r"ë§.*ì–´ëˆŒ", r"ë°œìŒ.*ì´ìƒ",
            r"ë°œì‘", r"ê²½ë ¨", r"stroke", r"ë‡Œì¡¸ì¤‘", r"ì‹ ê²½"
        ],
        "abdominal": [
            r"ë³µí†µ", r"ë°°.*ì•„íŒŒ", r"í† ", r"êµ¬í† ", r"í† í˜ˆ", r"í˜ˆë³€", r"ë©œë ˆë‚˜",
            r"ì†Œí™”", r"GI", r"melena", r"hematemesis", r"ë³µë¶€.*í†µì¦", r"ë³µë¶€í†µì¦"
        ],
        "bleeding": [
            r"ì¶œí˜ˆ", r"í”¼.*ë‚œ", r"ì½”í”¼", r"ì§€í˜ˆ.*ì•ˆë¨"
        ],
        "altered": [
            r"ì˜ì‹.*ë–¨ì–´", r"ì˜ì‹.*ì €í•˜", r"ì“°ëŸ¬ì§", r"ì‹¤ì‹ ", r"syncope", r"ì˜ì‹.*ë³€í™”", r"ë©˜íƒˆ.*ë³€í™”",
            r"ì˜ì‹.*ì†Œì‹¤"
        ],
        "trauma": [
            r"êµí†µì‚¬ê³ ", r"ì‚¬ê³ ", r"ë‚™ìƒ", r"ì ˆë‹¨", r"ê³¨ì ˆ", r"í™”ìƒ", r"ê³¨ë°˜",
            r"ë‘ë¶€ì†ìƒ", r"ì¶”ë½"
        ],
        "obgyn": [
            r"ì„ì‹ ", r"ì§„í†µ", r"ì¶œì‚°", r"ì§ˆì¶œí˜ˆ", r"ì‚°ê³¼", r"ë¶€ì¸ê³¼", r"ì„ì‚°"
        ],
        "pediatric": [
            r"ì†Œì•„", r"ì•„ê¸°", r"ì•„ì´", r"ì—´", r"ê³ ì—´", r"ê²½ë ¨", r"íƒˆìˆ˜"
        ],
        "psychiatric": [
            r"ìì‚´", r"ìš°ìš¸", r"í­ë ¥", r"í™˜ì²­", r"ë§ìƒ", r"ì •ì‹ ", r"í¥ë¶„",
            r"ê¸‰ì„±.*ì •ì‹ ë³‘"
        ],
    }

    # -------------------------
    # ğŸ”¥ â‘  ëª…ì‹œì  ì£¼í˜¸ì†Œ ì¸ì‹ (ìµœìš°ì„ )
    # -------------------------
    explicit_cc_patterns = [
        r"(ì£¼í˜¸ì†Œ|ì£¼í˜¸|ì£¼ëœ\s*ì¦ìƒ|ì£¼ëœ\s*í˜¸ì†Œ|ì£¼\s*ì¦ìƒ|ì£¼ëœ\s*ë¬¸ì œ|ê°€ì¥\s*ë¶ˆí¸í•œ\s*ê³³|ê°€ì¥\s*ì•„í”ˆ\s*ê³³)[ì€ëŠ”]?\s*([ê°€-í£A-Za-z0-9\s]+)",
        r"([ê°€-í£A-Za-z0-9\s]+?)(?:ì„|ë¥¼)\s*í˜¸ì†Œ",
        r"([ê°€-í£A-Za-z0-9\s]+?)\s*ì†Œê²¬"
    ]

    explicit_cc_raw = None

    for ep in explicit_cc_patterns:
        m = re.search(ep, t)
        if m:
            if m.lastindex and m.lastindex >= 2:
                explicit_cc_raw = m.group(2).strip()
            else:
                explicit_cc_raw = m.group(1).strip()
            break

    # ëª…ì‹œì  ì£¼í˜¸ì†Œ í‘œí˜„ì´ ë°œê²¬ëœ ê²½ìš° â†’ ë§¤ì¹­ ì‹œë„
    cc_found = False
    if explicit_cc_raw:
        for cc, patterns in cc_patterns.items():
            if match_any(patterns, explicit_cc_raw):
                S["chief_complaint"] = cc
                cc_found = True
                break  # ë§¤ì¹­ë˜ë©´ ë£¨í”„ íƒˆì¶œ (í•¨ìˆ˜ ë¦¬í„´ X)

    # ëª…ì‹œì  ì£¼í˜¸ì†Œê°€ ì—†ì—ˆì„ ë•Œë§Œ ì „ì²´ í…ìŠ¤íŠ¸ ìŠ¤ìº”
    if not cc_found:
        for cc, patterns in cc_patterns.items():
            if match_any(patterns, t):
                S["chief_complaint"] = cc
                break

    # ------------------------- ì‚¬ê³ ê¸°ì „(Mechanism) -------------------------
    # â˜… ìœ„ì—ì„œ ë¦¬í„´í•˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ì´ì œ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë¨
    if match_any(PATTERNS["mechanism"], t):
        S["mechanism"] = True

    # -------------------------
    # ğŸ”¥ ë³‘ì› ë‹¨ì–´ + ë¶€ì •í‘œí˜„ â†’ followup ê°•ì œ ì—†ìŒ
    # -------------------------
    hospital_none_patterns = [
        r"ë³‘ì›.{0,20}(ì•ˆ\s*ë‹¤ë‹ˆ|ì•ˆ\s*ë‹¤ë…€|ì•ˆ\s*ë‹¤ë…”|ë‹¤ë‹Œ\s*ê³³\s*ì—†|ë‹¤ë‹ˆëŠ”\s*ê³³\s*ì—†|ë”°ë¡œ\s*ì—†|ì—†[ì–´ìš”ìŠµë‹ˆë‹¤]*)",
        r"(ì•ˆ\s*ë‹¤ë‹ˆ|ì•ˆ\s*ë‹¤ë…€|ì•ˆ\s*ë‹¤ë…”|ë‹¤ë‹Œ\s*ê³³\s*ì—†|ë‹¤ë‹ˆëŠ”\s*ê³³\s*ì—†|ë”°ë¡œ\s*ì—†|ì—†[ì–´ìš”ìŠµë‹ˆë‹¤]*)\s*ë³‘ì›",
        r"í‰ì†Œ\s*ë‹¤ë‹ˆëŠ”\s*ë³‘ì›\s*ì—†",
        r"ë‹¤ë‹ˆë˜\s*ë³‘ì›\s*ì—†",
        r"ë³‘ì›\s*ëª¨ë¥´ê² ",
        r"ë³‘ì›\s*ëª¨ë¦„",
        r"ë³‘ì›\s*ì—†",
    ]

    hospital_forced_none = False

    for pattern in hospital_none_patterns:
        if re.search(pattern, t, re.IGNORECASE):
            S["followup_raw"] = None
            hospital_forced_none = True
            break

    # ë³‘ì› ì—†ìŒì´ ëª…í™•íˆ ê°ì§€ë˜ë©´ ë³‘ì› íŒŒì‹± ì „ì²´ ìŠ¤í‚µ
    if not hospital_forced_none:
        # -------------------------
        # ğŸ”½ ê¸°ì¡´ ë³‘ì› íŒŒì‹± ë¡œì§
        # -------------------------
        followup_raw = None

        hospital_patterns = [
            r"(?:ê¸°ì¡´|í‰ì†Œ|ë‹¤ë‹ˆë˜|ì£¼ë¡œ|ë‹¨ê³¨)\s*.*?([ê°€-í£A-Za-z0-9\s]+ë³‘ì›)",
            r"([ê°€-í£A-Za-z0-9\s]+ë³‘ì›)\s*ë‹¤ë‹ˆ",
            r"(?:ë³‘ì›)\s*([ê°€-í£A-Za-z0-9\s]+ë³‘ì›)\s*ë‹¤ë…”",
        ]

        for hp in hospital_patterns:
            m = re.search(hp, t)
            if m:
                followup_raw = m.group(1).strip()
                break

        # follow-up ë³‘ì› íŒ¨í„´
        followup_patterns = [
            r'([ê°€-í£A-Za-z0-9\s]+ë³‘ì›).*?(íŒ”ë¡œì—…|íŒ”ë¡œìš°ì—…|follow[-\s]?up|ì¶”ì |ì¶”ì ê´€ì°°|ì™¸ë˜|ê²½ê³¼ê´€ì°°)',
            r'(íŒ”ë¡œì—…|íŒ”ë¡œìš°ì—…|follow[-\s]?up|ì¶”ì |ì¶”ì ê´€ì°°|ì™¸ë˜).*?([ê°€-í£A-Za-z0-9\s]+ë³‘ì›)',
            r'([ê°€-í£A-Za-z0-9\s]+ë³‘ì›).*(ë³´ë˜|ë‹¤ë‹ˆë˜|ë‹¤ë…”ë˜|ê´€ë¦¬ë°›ëŠ”|ì§„ë£Œë°›ëŠ”)',
        ]

        if followup_raw is None:
            for fp in followup_patterns:
                m = re.search(fp, t)
                if m:
                    if m.lastindex and m.group(1) and "ë³‘ì›" in m.group(1):
                        followup_raw = m.group(1).strip()
                    elif m.lastindex and m.group(2):
                        followup_raw = m.group(2).strip()
                    break

        S["followup_raw"] = followup_raw


    # ------------------------- ì´ì†¡/ìš”ì²­ ì‚¬í•­ (ë¬¸ì¥ ì „ì²´ ì¶”ì¶œ) -------------------------
    requirement_keywords = [
        "ìš”ì²­", "í•„ìš”", "ì „ì›", "ì´ì†¡", "ìš”êµ¬",
        "ì§‘ì¤‘ì¹˜ë£Œ", "ê´€ì°° í•„ìš”", "ì²˜ì¹˜ í•„ìš”",
        "í•„ìš”í•©ë‹ˆë‹¤", "í•„ìš”í•  ê²ƒ ê°™", "í•„ìš”í•´ ë³´"
    ]

    requirement = None
    sentences = re.split(r'[.!?]\s*', t)

    for sent in sentences:
        for kw in requirement_keywords:
            if kw in sent:
                requirement = sent.strip()
                break
        if requirement:
            break

    S["requirement"] = requirement

    return S

# -------------------- R --------------------
def parse_response_v3(text: str) -> dict:
    R = {
        "oxygen_lpm": None,
        "fluids": False,
        "CPR": 0,           # í•­ìƒ 0 ë˜ëŠ” 1ë¡œ ì €ì¥
        "AED_shocks": 0,
        "response": None
    }

    t = text.lower()

    # ì‚°ì†Œ
    o2 = re.search(r'ì‚°ì†Œ\s*(\d+)', t)
    if o2:
        R["oxygen_lpm"] = int(o2.group(1))

    # ìˆ˜ì•¡
    if "ìˆ˜ì•¡" in t or "ì •ë§¥ë¡œ" in t:
        R["fluids"] = True

    # CPR ì²˜ë¦¬ -------------------------
    if "cpr" in t:
        neg = [
            "í•˜ì§€ ì•Š", "ì•ˆ í–ˆ", "ì•ˆí•¨", "ì•ˆ í•˜", "ì—†ì—ˆ",
            "ë¯¸ì‹œí–‰", "ì‹œí–‰í•˜ì§€ ì•Š", "ì‹œí–‰ ì•ˆ", "í•„ìš” ì—†ì–´",
            "ì•ˆ í–ˆìŠµë‹ˆë‹¤", "ì•ˆí–ˆìŠµë‹ˆë‹¤", "ì•ˆí–ˆìŠµë‹ˆë‹¤"
        ]
        if any(n in t for n in neg):
            R["CPR"] = 0
        else:
            R["CPR"] = 1
    # -----------------------------------

    # AED shock
    m = re.search(r'(aed|ì œì„¸ë™).{0,5}(\d+)\s*íšŒ', t)
    if m:
        R["AED_shocks"] = int(m.group(2))

    # ë°˜ì‘
    if "í˜¸ì „" in t or "ë‚˜ì•„ì¡Œ" in t:
        R["response"] = "improved"
    elif "ì•…í™”" in t:
        R["response"] = "worsened"
    elif "ë³€í™” ì—†" in t:
        R["response"] = "no_change"

    return R


# -------------------- SBAR í†µí•© --------------------
def parse_sbar_v3(text: str) -> dict:
    return {
        "S": parse_situation_v3(text),
        "B": parse_background_v3(text),
        "A": parse_assessment_v3(text),
        "R": parse_response_v3(text),
    }


# ============================================================
# 3. KTAS 1/2/3 ê²°ì •
# ============================================================
def decide_ktas_1to3(sbar: dict, raw_text: str):
    S, B, A, R = sbar["S"], sbar["B"], sbar["A"], sbar["R"]

    level = 3
    reasons = []

    sbp = A["BP_sys"]
    hr = A["HR"]
    bt = A["BT"]
    rr = A["RR"]
    spo2 = A["SpO2"]

    # =====================================================
    # 0) CPR / AED â†’ ë¬´ì¡°ê±´ KTAS 1
    # =====================================================
    if R["CPR"] == 1 or R["AED_shocks"] >= 1:
        return 1, "CPR ë˜ëŠ” AED ì¶©ê²© ì‹œí–‰ â†’ KTAS 1"

    # =====================================================
    # 1) AVPU (ì˜ì‹)
    # =====================================================
    if A["AVPU"] == "U":
        return 1, "ì˜ì‹ ì—†ìŒ(AVPU=U) â†’ KTAS 1"

    if A["AVPU"] in ["V", "P"]:
        level = min(level, 2)
        reasons.append(f"ì˜ì‹ ì €í•˜(AVPU={A['AVPU']}) â†’ KTAS 2")

    # =====================================================
    # ì‡¼í¬(Early Shock) íŒì • â€“ ê¸°ì¤€ 2ê°œ ì´ìƒì´ë©´ KTAS 1
    # =====================================================
    shock_count = 0

    # SBP 80~90
    if sbp is not None and 80 <= sbp < 90:
        shock_count += 1

    # HR > 130
    if hr is not None and hr > 130:
        shock_count += 1

    # RR > 30
    if rr is not None and rr > 30:
        shock_count += 1

    # SpO2 85~90
    if spo2 is not None and 85 <= spo2 < 90:
        shock_count += 1

    # í”¼ë¶€ ì°½ë°±/ë°œí•œ
    if "ì°½ë°±" in raw_text or "ì°½ë°±í•´" in raw_text or "ì‹ì€ë•€" in raw_text or "ë°œí•œ" in raw_text:
        shock_count += 1

    # CRT > 3ì´ˆ
    if "ëª¨ì„¸í˜ˆê´€" in raw_text or "capillary" in raw_text or "CRT" in raw_text:
        m = re.search(r'(crt|ëª¨ì„¸í˜ˆê´€)\D*(\d+)', raw_text, re.IGNORECASE)
        if m and int(m.group(2)) >= 3:
            shock_count += 1

    if shock_count >= 2:
        return 1, f"ì‡¼í¬ ì˜ì‹¬ ê¸°ì¤€ {shock_count}ê°œ ì¶©ì¡± â†’ KTAS 1"

    # =====================================================
    # 2) í˜ˆì—­í•™ ìƒíƒœ (í˜ˆì•• + ì‡¼í¬ ì§•í›„ + ë§¥ë°•)
    # =====================================================
    # --- 1ë‹¨ê³„ ---
    if sbp is not None and sbp < 80:
        return 1, f"ì‹¬í•œ ì €í˜ˆì••(SBP={sbp}) â†’ KTAS 1"

    shock_keywords = ["ì‡¼í¬", "shock", "í˜ˆì••ì´ ì•ˆ ì¡í˜€", "ìˆœí™˜ ì•ˆ ë¨", "ë§ì´ˆ ëƒ‰ê°"]
    if any(k in raw_text for k in shock_keywords):
        return 1, "ì‡¼í¬ ë˜ëŠ” ìˆœí™˜ë¶•ê´´ ì˜ì‹¬ í‘œí˜„ â†’ KTAS 1"

    # --- 2ë‹¨ê³„ ---
    if sbp is not None and 80 <= sbp <= 100:
        level = min(level, 2)
        reasons.append(f"ì €í˜ˆì••(SBP={sbp}) â†’ KTAS 2")

    if hr is not None and (hr >= 130 or hr <= 40):
        level = min(level, 2)
        reasons.append(f"ì‹¬í•œ ë§¥ë°• ì´ìƒ(HR={hr}) â†’ KTAS 2")

    # =====================================================
    # 3) í˜¸í¡ ìƒíƒœ (SpO2)
    # =====================================================
    if spo2 is not None:
        if spo2 < 90:
            return 1, f"ì‹¬í•œ ì €ì‚°ì†Œì¦(SpOâ‚‚={spo2}) â†’ KTAS 1"
        elif 90 <= spo2 < 92:
            level = min(level, 2)
            reasons.append(f"ê²½ë„ ì €ì‚°ì†Œì¦(SpOâ‚‚={spo2}) â†’ KTAS 2")

    # =====================================================
    # 4) ì²´ì˜¨ / SIRS
    # =====================================================
    sirs_count = 0

    if bt is not None and (bt >= 38 or bt <= 36):
        sirs_count += 1
    if hr is not None and hr > 90:
        sirs_count += 1
    if rr is not None and rr > 20:
        sirs_count += 1

    if sirs_count >= 3:
        level = min(level, 2)
        reasons.append(f"SIRS ê¸°ì¤€ {sirs_count}ê°œ ì¶©ì¡± â†’ KTAS 2")
    elif sirs_count == 2:
        level = min(level, 3)
        reasons.append(f"SIRS ê¸°ì¤€ 2ê°œ ì¶©ì¡± â†’ KTAS 3")

    # =====================================================
    # 5) ì¶œí˜ˆì„± ì§ˆí™˜ (í‚¤ì›Œë“œ ê¸°ë°˜)
    # =====================================================
    bleeding_text = raw_text

    severe_bleed_keywords = [
        "ëŒ€ëŸ‰", "ë¶„ì¶œ", "ê³¼ë‹¤ì¶œí˜ˆ", "ì‹¬ë¶€", "ë™ë§¥",
    ]
    mild_bleed_keywords = ["ì½”í”¼", "ë‹¨ìˆœ", "ì—´ìƒ", "ì›”ê²½", "ê´€ì ˆ"]

    if any(k in bleeding_text for k in severe_bleed_keywords):
        level = min(level, 2)
        reasons.append("ì¤‘ë“±ë„~ì¤‘ì¦ ì¶œí˜ˆ ì†Œê²¬ â†’ KTAS 2")
    elif any(k in bleeding_text for k in mild_bleed_keywords):
        reasons.append("ê²½ë¯¸ ì¶œí˜ˆ â†’ KTAS 3")

    # =====================================================
    # 6) ì‚¬ê³ ê¸°ì „ (mechanism)
    # =====================================================
    if S["mechanism"]:
        level = min(level, 2)
        reasons.append("ê³ ìœ„í—˜ ì‚¬ê³ ê¸°ì „(Mechanism of Injury) â†’ KTAS 2")

    # =====================================================
    # 7) ê°€ìŠ´í†µì¦ + ê³ ìœ„í—˜êµ°
    # =====================================================
    is_chest_pain = (
        S["chief_complaint"] == "chest_pain"
        or match_any(PATTERNS["chest_pain"], raw_text)
    )

    if is_chest_pain:
        chest_risk_factors = []

        # â‘  ì••ë°•ê°/ì¡°ì„ (í†µì¦ ì–‘ìƒ)
        pressure_keywords = ["ì¡°ì´", "ì¡°ì—¬", "ì§“ëˆ„ë¥´", "ì••ë°•", "ì¥ì–´ì§œ",  "ë¬´ê±°ìš´"]
        if any(k in raw_text for k in pressure_keywords):
            chest_risk_factors.append("ì••ë°•ê°/ì¡°ì„")

        # â‘¡ ì‹ì€ë•€ ë™ë°˜
        if "ì‹ì€ë•€" in raw_text or "ë°œí•œ" in raw_text or "ì‹ì€ ë•€" in raw_text:
            chest_risk_factors.append("ì‹ì€ë•€ ë™ë°˜")

        # â‘¢ í†µì¦ ê°•ë„ (NRS â‰¥ 7)
        if A["pain_nrs"] is not None and A["pain_nrs"] >= 7:
            chest_risk_factors.append(f"ì‹¬í•œ í†µì¦(NRS={A['pain_nrs']})")

        # â‘£ ì‹¬ê·¼í—ˆí˜ˆ ì˜ì‹¬ ì†Œê²¬ (í‚¤ì›Œë“œ ë§¤ì¹­)
        #    (ì‹¬ì „ë„, STë¶„ì ˆ, ì‹¬ê·¼ê²½ìƒ‰/í—ˆí˜ˆ ì–¸ê¸‰ ë“±)
        ischemia_keywords = ["ì‹¬ê·¼í—ˆí˜ˆ", "í—ˆí˜ˆ", "ST", "ì‹¬ê·¼ê²½ìƒ‰", "í˜‘ì‹¬ì¦", "ê´€ìƒë™ë§¥"]
        if any(k in raw_text for k in ischemia_keywords):
            chest_risk_factors.append("ì‹¬ê·¼í—ˆí˜ˆ ì˜ì‹¬ ì†Œê²¬")

        # ìœ„ ì¡°ê±´ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹í•˜ë©´ KTAS 2
        if chest_risk_factors:
            level = min(level, 2)
            reasons.append(f"ì „í˜•ì  í‰í†µ/ê³ ìœ„í—˜ ì†Œê²¬({', '.join(chest_risk_factors)}) â†’ KTAS 2")

    # =====================================================
    # 8) ê¸°ë³¸ ê²°ê³¼
    # =====================================================
    if not reasons:
        reasons.append("íŠ¹ì´ ìœ„í—˜ ì†Œê²¬ ì—†ìŒ â†’ KTAS 3")

    return level, "\n".join(reasons)

def build_stage2_payload(ktas_result: dict) -> dict:
    """
    Step2(ë³‘ì› í•„í„°ë§ ì—”ì§„)ì— ë„˜ê¸¸ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ìƒì„±
    """
    return {
        "ktas_level": ktas_result["ktas"],                # 1 / 2 / 3
        "chief_complaint": ktas_result["chief_complaint"], # dyspnea / chest_pain ...
        "hospital_followup": ktas_result["followup_hospital"]  # ì •ì‹ ë³‘ì›ëª… or None
    }


def ktas_from_audio(audio_source: Union[str, IO]) -> dict:
    print(f"[INFO] ìŒì„± ì¸ì‹ ì¤‘... ({audio_source})")
    text = speech_to_text(audio_source)

    print("\n[STT ê²°ê³¼]")
    print(text)

    # â‘  LLM ë³´ì •
    clean_text = llm_clean_text(text)

    print("\n[LLM ë³´ì • í›„ ë¬¸ì¥]")
    print(clean_text)

    # â‘¡ SBAR íŒŒì‹±
    sbar = parse_sbar_v3(clean_text)

    print("\n[SBAR ê²°ê³¼]")
    print(sbar)

    # KTAS íŒë‹¨
    level, reason = decide_ktas_1to3(sbar, clean_text)

    print("\n===== ìµœì¢… KTAS =====")
    print(f"KTAS = {level}")
    print(reason)

    ko_cc = CHIEF_COMPLAINT_KO.get(sbar["S"].get("chief_complaint"))
    raw_hospital = sbar["S"].get("followup_raw")
    final_hospital = best_match_hospital(raw_hospital, SEOUL_HOSPITAL_DB)

    print("\n===== ì¶”ê°€ ì •ë³´ =====")
    print(f"ì£¼í˜¸ì†Œ : {ko_cc}")
    print(f"ì›ë‚´/ê¸°ì¡´ ë‹¤ë‹ˆë˜ ë³‘ì› : {final_hospital or 'ì •ë³´ ì—†ìŒ'}")

    requirement = sbar["S"].get("requirement") or "None"
    print(f"ìš”êµ¬ì‚¬í•­ : {requirement}")

    return {
        "text": clean_text,
        "sbar": sbar,
        "ktas": level,
        "reason": reason,
        "chief_complaint": sbar["S"]["chief_complaint"],
        "followup_hospital_raw": raw_hospital,
        "followup_hospital": final_hospital,
    }



